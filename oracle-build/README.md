## Требования при работе
Для сборки SQL на агенте должен быть установлен GIT. 
Для тестирования и наката должен быть клиент SQLPLUS (вероятно, в следующей версии сборщика это требование будет убрано и выполнение скриптов будет только через SSH на удаленной БД).

## Сборка ( задача build )

В первую очередь необходимо получить новую версию скриптов (sql файлов). Для этого в GIT имеется структура директорий, с помощью которой сборщик может легко собрать набор файлов в правильном порядке для установки на бой и тестовый сервер. Принцип работы следующий:

### Настройки

В build.gradle необходимо указать собираемую версию проекта project.version , например, 1.0.0
Настроить очередность собираемых схем в переменной userOrdering , например SYSTEM, SYS, TRCARD, ETICKET, GATE. Схемы должны быть указаны в очередности своего наката и прямой зависимости ( главные схемы впереди). Схемы, не указанные в данной переменной считаются равнозначными и накатываются в последнюю очередь в произвольном порядке
Настроить очередность собираемых объектов в переменной dirOrdering (данное правило распространяется на все схемы и является основополагающим в сборке). Например BEFORE, TYPES, PROCEDURES, FUNCTIONS, VIEWS, MVIEWS, TRIGGERS, PACKAGE_BODIES, AFTER (приведенный пример является конфигом по умолчанию исходя из лучших практик, однако можно расширить этот список, добавив в него ряд объектов, которые также должны собираться в определенной последовательности,  к примеру, SEQUENCES).

### Принцип работы

В момент запуска команды build выполняется команда git diff --name-status master db ( где db - директория git, в которой хранятся схемы к объектов, master - локальная ветка master, которая должна содержать последнюю версию origin/master - т.е. необходимо правильным образом настроить сервер сборки bamboo чтобы в момент выкачивания последнего коммита ветка master также выкачивалась до последней версии ). По данной команде выбираются все измененные и вновь добавленные файлы в проект в сравнении с последней выпущенной версией ( версией, которая закомичена в ветку master )
Выбранные выше файлы копируются в директорию сборки buildDir сохраняя свою структуру
Создается файл do.sql, внутри которого создаются подключения к БД к каждой схеме в порядке, указанном в настройке. Для каждой схемы прописывается выполнение файлов, согласно настройки очередности наката. В начале файла прописывается исполнение файла конфигурации conf.sql. В конце прописывается для каждой схемы выполнение файла recompile.sql для починки инвалидных объектов
```sql
SET SERVEROUTPUT ON SIZE 1000000
SET VERI OFF
SET FEEDBACK ON
SET TERMOUT ON
spool install.log
@@conf.sql
PROMPT SYSTEM
conn SYSTEM/SYSTEM@myserver
@@db/SYSTEM/00_BEFORE/1.0.0.sql
 
PROMPT SYS
conn SYS/SYS@myserver AS SYSDBA
@@db/SYS/00_BEFORE/1.0.0.sql
 
PROMPT Invalid object after recompiling below:
PROMPT LIMON:conn LIMON/LIMON@pinky.tcpatch
@@recompile.sql
spool off
exit
```
Создается файл conf.sql в котором прописываются переменные подключения к БД и параметры создания схем ( по умолчанию для CI-сервера )
 
```sql
define MYSCHEME_PWD="MYSCHEME"
define MYSCHEME_TBS="MYSCHEME"
define MYSCHEME_TMP_TBS="TEMP"
```
Создается файл recompile.sql для перекомпиляции инвалидных объектов в схемах
```sql
declare
procedure exec_cmd( p$cmd IN VARCHAR2 )
IS
BEGIN
   execute immediate p$cmd;
exception
   when others then
      dbms_output.put_line( sqlerrm );
END exec_cmd;
procedure compile_all(p$ob_type IN VARCHAR2, p$dop IN VARCHAR2 DEFAULT '' )
IS
begin
for c in (
select 'alter ' || p$ob_type || ' '||object_name||' compile'||p$dop cmd
from user_objects
where object_type = p$ob_type || p$dop
 and status = 'INVALID'
) loop
   exec_cmd(c.cmd);
end loop;
end compile_all;
begin
   compile_all('TYPE');
   compile_all('TYPE',' BODY');
   compile_all('VIEW');
   compile_all('PACKAGE');
   compile_all('PACKAGE',' BODY');
   compile_all('FUNCTION');
   compile_all('PROCEDURE');
   compile_all('TRIGGER');
   compile_all('MATERIALIZED VIEW');
   compile_all('OPERATOR');
for c in (
select 'create or replace synonym ' || synonym_name || ' for '||table_owner||'.'||table_name cmd
from user_synonyms
) loop
   exec_cmd(c.cmd);
end loop;
end;
/
set termout on
set verify on
set heading on
column object_name format A30
column object_type format A30
select object_name,object_type from user_objects
where status = 'INVALID';
```
список файлов с файлом do.sql во главе зипуется в артифакт

## Деплой ( задача install )

Деплой необходим для проверки установки сборки на CI - сервере на базе данных, предназначенной для автоматического тестирования. для этого по ssh сборщик подключается к удаленному серверу, на котором должен быть настроен файл для отката, например, такой (в дальнейшем это будет переработано в сборщике): 
flashback.sh  Развернуть исходный код

### Настройки

В build.gradle настраиваются следующие переменные:
dbhost = "pinky.tcpatch" - задаем хост базы данных, на которую будет производиться установка
restorePoint = "LASTPATCH" - где LASTPATCH тэг, до которого необходимо откатывать базу данных
 
def dbhost = "myserver"
def restorePoint = "LASTPATCH"

### Порядок работы
Происходит подключение по SSH на удаленный сервер, на котором установлена БД необходимой версии
Выполняется файл flashback.sh, который откатывает базу данных до состояния последнего актуального патча ( из флешбека, либо восстанавливает из бэкапа ) по определенному тэгу
После того, как база откачена до "чистого" состояния, на этот сервер выполняется do.sql и накатываются все изменения из сборки
В случае, если после установки сборки в базе остались инвалидные объекты, либо в процессе наката были ошибки класса ERROR - сборка должна свалиться с ошибкой ( TODO !!! )

## Тестирование ( задача test ) TODO!!!

Задача предназначена для функционального/модульного тестирования Базы данных

### Порядок работы

Из директории GIT dbtest происходит установка тестовых пакетов на БД
Запускаются тесты, которые должны вернуть свои результаты в файлы test-***result.xml в формате jUnit

### Очередность работ

В директории TC-Processing/DB_CORE создаем директорию db
В директории db размещаем схемы базы. Схемы должны точно соответствовать схемам в базе данных. например:
- SYS
- SYSTEM
- MYSDCHEME

В каждой директории должны быть поддиректории следующего состава:
* BEFORE - скрипты, которые должны быть выполнены до наката DDL
* TYPES  - типы ( есть открытый вопрос по переустановке типов, т.к. они генерятся через udtgen )
* PACKAGES - спецификации пакетов
* PROCEDURES - процедуры
* FUNCTIONS - функции
* VIEWS - вьюхи
* MVIEWS - материализованные вьюхи
* TRIGGERS - триггеры
* PACKAGE_BODIES - тело пакетов
* AFTER - скрипты, которые должны быть выполнены после наката DDL

Примечание: создавать директории необходимо только в случае, если есть объекты данного типа в схеме. Возможны дополнительные директории, если требуется упорядочить дополнительный состав объектов ( например, SEQUENCES )
